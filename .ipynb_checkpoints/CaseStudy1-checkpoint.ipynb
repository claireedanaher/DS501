{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 21, **BEFORE the beginning of class at 6:00pm**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "   Claire Danaher\n",
    "    \n",
    "   Janvi Kothari\n",
    "        \n",
    "   Erin Teeple\n",
    "   \n",
    "   Renee Sweeney\n",
    "   \n",
    "   Jonathan  Friedman\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# LIBRARY IMPORTS#\n",
    "###################\n",
    "import twitter\n",
    "import json\n",
    "\n",
    "\n",
    "###################\n",
    "# CUSTOM FUNCTIONS#\n",
    "###################\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#TAKES RAW TWITTER DATA AND PRINTS JSON#\n",
    "##################  START   #######################################################\n",
    "def pp(invar):\n",
    "    f= json.dumps(invar, indent=1)\n",
    "    print(f)\n",
    "##################   END    ##########################################\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#CONNECT TO TWITTER API####\n",
    "##################  START   ############################################\n",
    "def oauth():\n",
    "    CONSUMER_KEY = 'zkX1ZDln052pgUIllkW7Dwd1s'\n",
    "    CONSUMER_SECRET ='kLVBs3vAosgAHBEiSb1jDtD4QARH6kKs5CxmvvcGTFfEhnsNF8'\n",
    "    OAUTH_TOKEN = '906043503720808448-tXaAnPREpAbuWPCgMO7F1IDACp0ONfg'\n",
    "    OAUTH_TOKEN_SECRET = 'Js5qQUODaQXFrnANeyyjxvQ2j4u4zfW4Vhkh1Mf3y9WZ4'\n",
    "\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "####################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "#KEYWORD SEARCH\n",
    "#q=keyword\n",
    "#count\n",
    "##################  START   ############################################\n",
    "def twitter_search(q, count, twitter_api, **kw):\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "    statuses = search_results['statuses']\n",
    "\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError: # No more results when next_results doesn't exist\n",
    "            break\n",
    "\n",
    "        kwargs = dict([ kv.split('=') \n",
    "            for kv in next_results[1:].split(\"&\") ])\n",
    "    \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "    return statuses\n",
    "###################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "#EXPORT JSON FILE\n",
    "#invar=variable containing data to be converted to json\n",
    "#filename=file name for the json data to be save to\n",
    "##################  START   ############################################\n",
    "def json_export(invar,filename):\n",
    "    data= json.dumps(invar, indent=1)\n",
    "    file = open(filename,'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "###################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "################        MAIN FUNCTIOn   ############################\n",
    "\n",
    "def main():\n",
    "    twitter_api=oauth()\n",
    "    search=['bitcoin','XRP','etherium','litecoin','namecoin']\n",
    "    result=[]\n",
    "    for i in search:\n",
    "            result+=twitter_search(i,1000,twitter_api)\n",
    "    json_export(result,'results_091517_9AM.txt')\n",
    "\n",
    "            \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "# converts .txt file into json structure\n",
    "file = \"results_091317_7PM.txt\"\n",
    "with open(file) as raw_data:\n",
    "    parsed_data = json.load(raw_data)\n",
    "\n",
    "# finds indices of repeated tweets\n",
    "texts = []\n",
    "repeated_indices = []\n",
    "for index in range(len(parsed_data)):\n",
    "    text = parsed_data[index]['text']\n",
    "    if text in texts:\n",
    "        repeated_indices.append(index)\n",
    "    else:\n",
    "        texts.append(text)\n",
    "\n",
    "# deletes repeated tweets\n",
    "for index in sorted(repeated_indices, reverse = True): \n",
    "    del parsed_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words         Count\n",
      "--------------  -------\n",
      "namecoin           1613\n",
      "1                  1046\n",
      "usd                1021\n",
      "0                   600\n",
      "cryptocurrency      565\n",
      "https               554\n",
      "nmc                 530\n",
      "co                  523\n",
      "30                  505\n",
      "mins                496\n",
      "bitcoin             344\n",
      "rt                  299\n",
      "litecoin            284\n",
      "changed             251\n",
      "increased           246\n",
      "btc                 225\n",
      "xrp                 217\n",
      "ltc                 169\n",
      "ripple              133\n",
      "eth                 110\n",
      "ethereum            106\n",
      "price                88\n",
      "crypto               84\n",
      "blockchain           60\n",
      "etc                  60\n",
      "etherium             60\n",
      "dash                 57\n",
      "neo                  44\n",
      "61                   40\n",
      "2                    39\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top30words(json_tweet_data):\n",
    "    # gathers the text from each tweet into a list, all converted to lowercase\n",
    "    all_tweets = []\n",
    "    for tweet in json_tweet_data:\n",
    "        all_tweets.append(tweet['text'].lower())\n",
    "    \n",
    "    # counts the number of words in each tweet's text\n",
    "    bag_of_words = [collections.Counter(re.findall(r'\\w+', text)) for text in all_tweets]\n",
    "    # collects all words and word counts together\n",
    "    bags_sum = sum(bag_of_words, collections.Counter())\n",
    "    \n",
    "    # loads English stopwords and removes them from bag of words\n",
    "    with open(\"stopwords/english\") as file:\n",
    "        stopword_list = file.readlines()\n",
    "    stopword_list = [newline.strip() for newline in stopword_list] \n",
    "    for stopword in stopword_list:\n",
    "        if stopword in bags_sum:\n",
    "            del bags_sum[stopword]\n",
    "            \n",
    "    # prints table of top 30 words and their counts\n",
    "    print(tabulate(bags_sum.most_common(30), headers=['Top Words', 'Count']))\n",
    "    print(\"\\n\")\n",
    "\n",
    "top30words(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mCount\tTop Tweets\u001b[0m\n",
      "\n",
      "6354\t\"RT @ErikVoorhees: My memory is failing, was it Bitcoin or was it JP Morgan that was bailed out by the government? https://t.co/DHqFzr5UJN\"\n",
      "1561\t\"RT @KingCrypto2: we're back in green. So one last time - if #Litecoin reaches $100 by Monday. I will send a $LTC to everyone who retweets +‚Ä¶\"\n",
      "839\t\"RT @pompous__p: It's my birthday today.\n",
      "So I'm giving away 10,000 $XRP to one lucky winner on Oct 1st!\n",
      "$XRP value will increase by then! GL‚Ä¶\"\n",
      "755\t\"RT @Qvolta_platform: Token launch coming soon!\n",
      "Meet a new service for P2P Cryptocurrency exchange!\n",
      "#ICO #cryptocurrency #bitcoin #etherium‚Ä¶\"\n",
      "664\t\"RT @mahomahotravel: ‰ªÆÊÉ≥ÈÄöË≤®„ÅÆÂèñÂºïÊâÄ„ÅØ‰Ωø„ÅÑ„ÇÑ„Åô„Åè„Å¶„Éá„Ç∂„Ç§„É≥„Åå„Åç„Çå„ÅÑ„Å™coincheck„ÇíÂèãÈÅî„Å´Âãß„ÇÅ„Çâ„Çå„Å¶‰Ωø„Å£„Å¶„Åæ„Åô(^o^)\n",
      "https://t.co/TcE7nwPaND\n",
      "\n",
      "#„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥ #„Ç§„Éº„Çµ„É™„Ç¢„É† #xem #nem #„Éç„É† #„É™„ÉÉ„Éó„É´ #xrp‚Ä¶\"\n",
      "647\t\"RT @hitbtc: Both @vergecurrency and @digibyte will be listed on HitBTC.\n",
      "\n",
      "Congratulations to both communities! We couldn't be happier. Could‚Ä¶\"\n",
      "643\t\"RT @777trillionaire: üöÄALERTüöÄ\n",
      "\n",
      "Giveaway! - If #Bitcoin hits $5k in a week - 1 RT wins 1 $BTC\n",
      "\n",
      "RT+Follow+Tag Friends to Win!\n",
      "üöÄ\n",
      "#LTC #eth #neo‚Ä¶\"\n",
      "634\t\"RT @SatoshiLite: I just published ‚ÄúMy Vision For SegWit And Lightning Networks On Litecoin And Bitcoin‚Äù https://t.co/lGOzDCxSrd\"\n",
      "623\t\"RT @cryptoscurated: GIVEAWAY üí∞7 days from now I'll be giving away 100 $OMG Just retweet and follow me to be in draw. $NEO $BTC $ETH $PAY $X‚Ä¶\"\n",
      "570\t\"RT @CryptoKirby: üöÄALERTüöÄ\n",
      "\n",
      "NEW Giveaway!- If #Bitcoin hits $5k in a week-1 RT wins 1 $BTC\n",
      "\n",
      "RT+Follow+Tag Friends to Win!\n",
      "üöÄ\n",
      "$ltc $eth $neo $o‚Ä¶\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "def top10retweeted(json_tweet_data):\n",
    "    # gathers number of retweet counts for each tweet into a list\n",
    "    retweet_counts = []\n",
    "    for tweet in json_tweet_data:\n",
    "        retweet_counts.append(tweet['retweet_count'])\n",
    "\n",
    "    # finds indices of top 10 retweet counts, ordered from most to least\n",
    "    top10indices = sorted(range(len(retweet_counts)), key = lambda i: retweet_counts[i])[:-11:-1]\n",
    "    \n",
    "    # prints table of top 10 tweets and their retweet counts\n",
    "    print(\"\\033[4mCount\\tTop Tweets\\033[0m\\n\")\n",
    "    for index in top10indices:\n",
    "        print(str(json_tweet_data[index]['retweet_count']) + \"\\t\\\"\" + json_tweet_data[index]['text'] + \"\\\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "top10retweeted(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Hashtags       Count\n",
      "---------------  -------\n",
      "#cryptocurrency      540\n",
      "#namecoin            501\n",
      "#nmc                 487\n",
      "#bitcoin              92\n",
      "#Bitcoin              81\n",
      "#litecoin             76\n",
      "#Litecoin             61\n",
      "#blockchain           35\n",
      "#Ethereum             33\n",
      "#ethereum             30\n",
      "\n",
      "\n",
      "Top Users Mentioned      Count\n",
      "---------------------  -------\n",
      "@MarketNmc                  32\n",
      "@Namecoin                   19\n",
      "@Ripple                     15\n",
      "@YouTube                     9\n",
      "@intuitecon                  9\n",
      "@ChartDavidson               9\n",
      "@RNR_0                       9\n",
      "@getongab                    9\n",
      "@SatoshiLite                 7\n",
      "@Naturlig2121                6\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "def top10hashtags_user_mentions(json_tweet_data):\n",
    "    user_list = []\n",
    "    hashtag_list = []\n",
    "    \n",
    "    for tweet in json_tweet_data:\n",
    "        # gathers the hashtags from each tweet into a list\n",
    "        hashtags = tweet['entities']['hashtags']\n",
    "        if len(hashtags):\n",
    "            for hashtag in hashtags:\n",
    "                hashtag_list.append(\"#\" + hashtag['text'])\n",
    "        \n",
    "        # gathers the users mentioned in each tweet into a list\n",
    "        user_mentions = tweet['entities']['user_mentions']\n",
    "        if len(user_mentions):\n",
    "            for user in user_mentions:\n",
    "                user_list.append(\"@\" + user['screen_name'])\n",
    "\n",
    "    # counts number of each hashtag\n",
    "    hashtag_count = collections.Counter(hashtag_list)\n",
    "    # prints table of top 10 hashtags with their counts\n",
    "    print(tabulate(hashtag_count.most_common(10), headers=['Top Hashtags', 'Count']))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # counts number of times each user is mentioned\n",
    "    user_count = collections.Counter(user_list)\n",
    "    # prints table of top 10 users mentioned and their counts\n",
    "    print(tabulate(user_count.most_common(10), headers=['Top Users Mentioned', 'Count']))\n",
    "    \n",
    "top10hashtags_user_mentions(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:\n",
    "\n",
    "### DS501 Case Study 1 Team ??\n",
    "\n",
    "#### where ?? is your team number.\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
